{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    # open file\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists in to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, valid_size):\n",
    "    X, y = load_data(\"processed.json\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size)\n",
    "\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_valid = X_valid[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = prepare_datasets(0.25, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(32, (2, 2), activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D((2,2), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=10, activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 2.4068 - accuracy: 0.2278 - val_loss: 1.9389 - val_accuracy: 0.3164\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 1.8738 - accuracy: 0.3539 - val_loss: 1.6620 - val_accuracy: 0.4166\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 1.6866 - accuracy: 0.3979 - val_loss: 1.4988 - val_accuracy: 0.4559\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 1.5590 - accuracy: 0.4470 - val_loss: 1.4060 - val_accuracy: 0.4973\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 1.4707 - accuracy: 0.4745 - val_loss: 1.3283 - val_accuracy: 0.5287\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 1.4106 - accuracy: 0.4939 - val_loss: 1.2884 - val_accuracy: 0.5507\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 1.3631 - accuracy: 0.5098 - val_loss: 1.2260 - val_accuracy: 0.5654\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 1.3047 - accuracy: 0.5348 - val_loss: 1.2010 - val_accuracy: 0.5748\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 1.2432 - accuracy: 0.5578 - val_loss: 1.1700 - val_accuracy: 0.5908\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 1.1944 - accuracy: 0.5774 - val_loss: 1.1314 - val_accuracy: 0.6175\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 1.1532 - accuracy: 0.5884 - val_loss: 1.0995 - val_accuracy: 0.6248\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 1.1211 - accuracy: 0.6082 - val_loss: 1.0832 - val_accuracy: 0.6422\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 1.0813 - accuracy: 0.6223 - val_loss: 1.0467 - val_accuracy: 0.6515\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 1.0467 - accuracy: 0.6314 - val_loss: 1.0447 - val_accuracy: 0.6469\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 1.0227 - accuracy: 0.6398 - val_loss: 1.0381 - val_accuracy: 0.6502\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.9985 - accuracy: 0.6510 - val_loss: 1.0075 - val_accuracy: 0.6709\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.9882 - accuracy: 0.6501 - val_loss: 0.9764 - val_accuracy: 0.6682\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.9294 - accuracy: 0.6700 - val_loss: 0.9672 - val_accuracy: 0.6836\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.9106 - accuracy: 0.6750 - val_loss: 0.9692 - val_accuracy: 0.6903\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.8933 - accuracy: 0.6889 - val_loss: 0.9276 - val_accuracy: 0.6943\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.8654 - accuracy: 0.6984 - val_loss: 0.9251 - val_accuracy: 0.7029\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.8431 - accuracy: 0.7062 - val_loss: 0.9110 - val_accuracy: 0.7083\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.8319 - accuracy: 0.7111 - val_loss: 0.8828 - val_accuracy: 0.7176\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.7970 - accuracy: 0.7187 - val_loss: 0.8759 - val_accuracy: 0.7103\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.8043 - accuracy: 0.7141 - val_loss: 0.8809 - val_accuracy: 0.7223\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.7843 - accuracy: 0.7308 - val_loss: 0.9055 - val_accuracy: 0.7069\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.7641 - accuracy: 0.7309 - val_loss: 0.8594 - val_accuracy: 0.7283\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.7414 - accuracy: 0.7445 - val_loss: 0.8678 - val_accuracy: 0.7130\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.7292 - accuracy: 0.7476 - val_loss: 0.8717 - val_accuracy: 0.7123\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.7204 - accuracy: 0.7496 - val_loss: 0.8315 - val_accuracy: 0.7283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235395629e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 8ms/step - loss: 0.8211 - accuracy: 0.7229\n",
      "Accuracy: 0.7228674292564392, Error: 0.8210904002189636\n"
     ]
    }
   ],
   "source": [
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Accuracy: {test_accuracy}, Error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"weights/cnn_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCCs from audio file\n",
    "def extract_mfccs_from_audio(\n",
    "    file_path,\n",
    "    segment_duration=3,\n",
    "    n_mfcc=13,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    sample_rate=22050,\n",
    "):\n",
    "    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "    # Calculate the number of samples per segment\n",
    "    samples_per_segment = sample_rate * segment_duration\n",
    "    expected_vector_length = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    mfccs = []\n",
    "    num_segments = int(len(signal) / samples_per_segment)\n",
    "\n",
    "    for s in range(num_segments):\n",
    "        start_sample = samples_per_segment * s\n",
    "        finish_sample = start_sample + samples_per_segment\n",
    "\n",
    "        if finish_sample > len(signal):\n",
    "            break\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=signal[start_sample:finish_sample],\n",
    "            sr=sr,\n",
    "            n_fft=n_fft,\n",
    "            n_mfcc=n_mfcc,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "        mfcc = mfcc.T\n",
    "\n",
    "        if len(mfcc) == expected_vector_length:\n",
    "            mfccs.append(mfcc.tolist())\n",
    "\n",
    "    return np.array(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "model.load_weights(\"weights/cnn_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [\n",
    "    \"blues\",\n",
    "    \"classical\",\n",
    "    \"country\",\n",
    "    \"disco\",\n",
    "    \"hiphop\",\n",
    "    \"jazz\",\n",
    "    \"metal\",\n",
    "    \"pop\",\n",
    "    \"reggae\",\n",
    "    \"rock\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step\n",
      "The predicted class for the song is: metal\n"
     ]
    }
   ],
   "source": [
    "mfccs = extract_mfccs_from_audio(\"sample songs/master.mp3\")\n",
    "predictions = model.predict(mfccs)\n",
    "\n",
    "probabilities = tf.nn.softmax(predictions, axis=-1)\n",
    "\n",
    "predicted_classes = np.argmax(probabilities, axis=1)\n",
    "\n",
    "class_counts = Counter(predicted_classes)\n",
    "most_common_class = mapping[class_counts.most_common(1)[0][0]]\n",
    "\n",
    "print(f\"The predicted class for the song is: {most_common_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
