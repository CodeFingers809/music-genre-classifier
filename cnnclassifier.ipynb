{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    # open file\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists in to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, valid_size):\n",
    "    X, y = load_data(\"processed.json\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size)\n",
    "\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_valid = X_valid[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = prepare_datasets(0.25, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(32, (2, 2), activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D((2,2), strides=(2,2), padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=10, activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1531 - loss: 2.6529 - val_accuracy: 0.3538 - val_loss: 1.8141\n",
      "Epoch 2/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3292 - loss: 1.9313 - val_accuracy: 0.4619 - val_loss: 1.5281\n",
      "Epoch 3/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4091 - loss: 1.6893 - val_accuracy: 0.4927 - val_loss: 1.4124\n",
      "Epoch 4/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4368 - loss: 1.5839 - val_accuracy: 0.5274 - val_loss: 1.3060\n",
      "Epoch 5/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4942 - loss: 1.4302 - val_accuracy: 0.5521 - val_loss: 1.2487\n",
      "Epoch 6/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4999 - loss: 1.3822 - val_accuracy: 0.5774 - val_loss: 1.2059\n",
      "Epoch 7/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5301 - loss: 1.3147 - val_accuracy: 0.6061 - val_loss: 1.1429\n",
      "Epoch 8/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5522 - loss: 1.2524 - val_accuracy: 0.6021 - val_loss: 1.1219\n",
      "Epoch 9/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5650 - loss: 1.1971 - val_accuracy: 0.6135 - val_loss: 1.0999\n",
      "Epoch 10/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5694 - loss: 1.2029 - val_accuracy: 0.6315 - val_loss: 1.0615\n",
      "Epoch 11/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5850 - loss: 1.1627 - val_accuracy: 0.6215 - val_loss: 1.0567\n",
      "Epoch 12/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6020 - loss: 1.1201 - val_accuracy: 0.6368 - val_loss: 1.0294\n",
      "Epoch 13/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6113 - loss: 1.0699 - val_accuracy: 0.6368 - val_loss: 1.0139\n",
      "Epoch 14/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6324 - loss: 1.0477 - val_accuracy: 0.6429 - val_loss: 1.0149\n",
      "Epoch 15/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6369 - loss: 1.0122 - val_accuracy: 0.6575 - val_loss: 0.9837\n",
      "Epoch 16/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6390 - loss: 1.0088 - val_accuracy: 0.6489 - val_loss: 0.9650\n",
      "Epoch 17/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6548 - loss: 0.9619 - val_accuracy: 0.6409 - val_loss: 0.9747\n",
      "Epoch 18/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6669 - loss: 0.9424 - val_accuracy: 0.6729 - val_loss: 0.9236\n",
      "Epoch 19/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6635 - loss: 0.9300 - val_accuracy: 0.6542 - val_loss: 0.9570\n",
      "Epoch 20/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6932 - loss: 0.8761 - val_accuracy: 0.6856 - val_loss: 0.8916\n",
      "Epoch 21/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6818 - loss: 0.8995 - val_accuracy: 0.6769 - val_loss: 0.9018\n",
      "Epoch 22/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6917 - loss: 0.8702 - val_accuracy: 0.6756 - val_loss: 0.9082\n",
      "Epoch 23/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6965 - loss: 0.8459 - val_accuracy: 0.6822 - val_loss: 0.9053\n",
      "Epoch 24/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7056 - loss: 0.8366 - val_accuracy: 0.6789 - val_loss: 0.8866\n",
      "Epoch 25/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7175 - loss: 0.7994 - val_accuracy: 0.6936 - val_loss: 0.8794\n",
      "Epoch 26/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7387 - loss: 0.7541 - val_accuracy: 0.7036 - val_loss: 0.8640\n",
      "Epoch 27/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7193 - loss: 0.7931 - val_accuracy: 0.6989 - val_loss: 0.8709\n",
      "Epoch 28/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 0.7650 - val_accuracy: 0.7043 - val_loss: 0.8564\n",
      "Epoch 29/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7367 - loss: 0.7365 - val_accuracy: 0.7056 - val_loss: 0.8404\n",
      "Epoch 30/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7373 - loss: 0.7438 - val_accuracy: 0.7036 - val_loss: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c79cdc8d00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.8526\n",
      "Accuracy: 0.7052462697029114, Error: 0.8486840724945068\n"
     ]
    }
   ],
   "source": [
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Accuracy: {test_accuracy}, Error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"weights/cnn_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCCs from audio file\n",
    "def extract_mfccs_from_audio(\n",
    "    file_path,\n",
    "    segment_duration=3,\n",
    "    n_mfcc=13,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    sample_rate=22050,\n",
    "):\n",
    "    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "    # Calculate the number of samples per segment\n",
    "    samples_per_segment = sample_rate * segment_duration\n",
    "    expected_vector_length = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    mfccs = []\n",
    "    num_segments = int(len(signal) / samples_per_segment)\n",
    "\n",
    "    for s in range(num_segments):\n",
    "        start_sample = samples_per_segment * s\n",
    "        finish_sample = start_sample + samples_per_segment\n",
    "\n",
    "        if finish_sample > len(signal):\n",
    "            break\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=signal[start_sample:finish_sample],\n",
    "            sr=sr,\n",
    "            n_fft=n_fft,\n",
    "            n_mfcc=n_mfcc,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "        mfcc = mfcc.T\n",
    "\n",
    "        if len(mfcc) == expected_vector_length:\n",
    "            mfccs.append(mfcc.tolist())\n",
    "\n",
    "    return np.array(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "model.load_weights(\"weights/cnn_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [\n",
    "    \"blues\",\n",
    "    \"classical\",\n",
    "    \"country\",\n",
    "    \"disco\",\n",
    "    \"hiphop\",\n",
    "    \"jazz\",\n",
    "    \"metal\",\n",
    "    \"pop\",\n",
    "    \"reggae\",\n",
    "    \"rock\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "The predicted class for the song is: metal\n"
     ]
    }
   ],
   "source": [
    "mfccs = extract_mfccs_from_audio(\"sample songs/master.mp3\")\n",
    "predictions = model.predict(mfccs)\n",
    "\n",
    "probabilities = tf.nn.softmax(predictions, axis=-1)\n",
    "\n",
    "predicted_classes = np.argmax(probabilities, axis=1)\n",
    "\n",
    "class_counts = Counter(predicted_classes)\n",
    "most_common_class = mapping[class_counts.most_common(1)[0][0]]\n",
    "\n",
    "print(f\"The predicted class for the song is: {most_common_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
