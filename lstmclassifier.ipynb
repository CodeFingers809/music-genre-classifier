{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    # open file\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists in to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, valid_size):\n",
    "    X, y = load_data(\"processed.json\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size)\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = prepare_datasets(0.25, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        \n",
    "        keras.layers.LSTM(units=64, return_sequences=True),\n",
    "        keras.layers.LSTM(units=64),\n",
    "        keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Dense(units=10, activation=\"linear\")\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.1370 - loss: 2.2733 - val_accuracy: 0.3144 - val_loss: 2.0577\n",
      "Epoch 2/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.3099 - loss: 1.9894 - val_accuracy: 0.3899 - val_loss: 1.7976\n",
      "Epoch 3/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.3652 - loss: 1.7638 - val_accuracy: 0.4433 - val_loss: 1.6250\n",
      "Epoch 4/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.4283 - loss: 1.6141 - val_accuracy: 0.4646 - val_loss: 1.5225\n",
      "Epoch 5/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.4710 - loss: 1.5229 - val_accuracy: 0.4927 - val_loss: 1.4483\n",
      "Epoch 6/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.4852 - loss: 1.4723 - val_accuracy: 0.5174 - val_loss: 1.3981\n",
      "Epoch 7/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.5039 - loss: 1.4053 - val_accuracy: 0.5214 - val_loss: 1.3614\n",
      "Epoch 8/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.5379 - loss: 1.3447 - val_accuracy: 0.5374 - val_loss: 1.3341\n",
      "Epoch 9/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.5459 - loss: 1.3365 - val_accuracy: 0.5407 - val_loss: 1.3147\n",
      "Epoch 10/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.5400 - loss: 1.3165 - val_accuracy: 0.5407 - val_loss: 1.3075\n",
      "Epoch 11/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.5650 - loss: 1.2505 - val_accuracy: 0.5574 - val_loss: 1.2825\n",
      "Epoch 12/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.5776 - loss: 1.2424 - val_accuracy: 0.5547 - val_loss: 1.2714\n",
      "Epoch 13/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.5790 - loss: 1.2111 - val_accuracy: 0.5661 - val_loss: 1.2548\n",
      "Epoch 14/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.5844 - loss: 1.1853 - val_accuracy: 0.5387 - val_loss: 1.3055\n",
      "Epoch 15/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.6045 - loss: 1.1644 - val_accuracy: 0.5641 - val_loss: 1.2375\n",
      "Epoch 16/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.6252 - loss: 1.1362 - val_accuracy: 0.5854 - val_loss: 1.2227\n",
      "Epoch 17/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6297 - loss: 1.1186 - val_accuracy: 0.5854 - val_loss: 1.2090\n",
      "Epoch 18/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6207 - loss: 1.1095 - val_accuracy: 0.5774 - val_loss: 1.2290\n",
      "Epoch 19/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6232 - loss: 1.1253 - val_accuracy: 0.5861 - val_loss: 1.2089\n",
      "Epoch 20/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6407 - loss: 1.0958 - val_accuracy: 0.6008 - val_loss: 1.1788\n",
      "Epoch 21/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6408 - loss: 1.0505 - val_accuracy: 0.5928 - val_loss: 1.1790\n",
      "Epoch 22/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6512 - loss: 1.0454 - val_accuracy: 0.5995 - val_loss: 1.1710\n",
      "Epoch 23/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6502 - loss: 1.0155 - val_accuracy: 0.5921 - val_loss: 1.1960\n",
      "Epoch 24/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6650 - loss: 0.9927 - val_accuracy: 0.5968 - val_loss: 1.1899\n",
      "Epoch 25/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6616 - loss: 1.0039 - val_accuracy: 0.6035 - val_loss: 1.1753\n",
      "Epoch 26/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6844 - loss: 0.9689 - val_accuracy: 0.6061 - val_loss: 1.1662\n",
      "Epoch 27/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6877 - loss: 0.9485 - val_accuracy: 0.6081 - val_loss: 1.1605\n",
      "Epoch 28/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6931 - loss: 0.9403 - val_accuracy: 0.5935 - val_loss: 1.1882\n",
      "Epoch 29/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.6928 - loss: 0.9301 - val_accuracy: 0.6075 - val_loss: 1.1584\n",
      "Epoch 30/30\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.7062 - loss: 0.8982 - val_accuracy: 0.6182 - val_loss: 1.1434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1931e3d33d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6186 - loss: 1.1379\n",
      "Accuracy: 0.6227473020553589, Error: 1.1224013566970825\n"
     ]
    }
   ],
   "source": [
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Accuracy: {test_accuracy}, Error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"weights/lstm_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCCs from audio file\n",
    "def extract_mfccs_from_audio(\n",
    "    file_path,\n",
    "    segment_duration=3,\n",
    "    n_mfcc=13,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    sample_rate=22050,\n",
    "):\n",
    "    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "    # Calculate the number of samples per segment\n",
    "    samples_per_segment = sample_rate * segment_duration\n",
    "    expected_vector_length = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    mfccs = []\n",
    "    num_segments = int(len(signal) / samples_per_segment)\n",
    "\n",
    "    for s in range(num_segments):\n",
    "        start_sample = samples_per_segment * s\n",
    "        finish_sample = start_sample + samples_per_segment\n",
    "\n",
    "        if finish_sample > len(signal):\n",
    "            break\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=signal[start_sample:finish_sample],\n",
    "            sr=sr,\n",
    "            n_fft=n_fft,\n",
    "            n_mfcc=n_mfcc,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "        mfcc = mfcc.T\n",
    "\n",
    "        if len(mfcc) == expected_vector_length:\n",
    "            mfccs.append(mfcc.tolist())\n",
    "\n",
    "    return np.array(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "model.load_weights(\"weights/lstm_weights.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [\n",
    "    \"blues\",\n",
    "    \"classical\",\n",
    "    \"country\",\n",
    "    \"disco\",\n",
    "    \"hiphop\",\n",
    "    \"jazz\",\n",
    "    \"metal\",\n",
    "    \"pop\",\n",
    "    \"reggae\",\n",
    "    \"rock\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "The predicted class for the song is: metal\n"
     ]
    }
   ],
   "source": [
    "mfccs = extract_mfccs_from_audio(\"sample songs/master.mp3\")\n",
    "predictions = model.predict(mfccs)\n",
    "\n",
    "probabilities = tf.nn.softmax(predictions, axis=-1)\n",
    "\n",
    "predicted_classes = np.argmax(probabilities, axis=1)\n",
    "\n",
    "class_counts = Counter(predicted_classes)\n",
    "most_common_class = mapping[class_counts.most_common(1)[0][0]]\n",
    "\n",
    "print(f\"The predicted class for the song is: {most_common_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
